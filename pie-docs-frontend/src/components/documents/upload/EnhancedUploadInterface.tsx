import React, { useState, useCallback } from 'react';
import { useTheme } from '@/contexts/ThemeContext';
import UploadZone from '../UploadZone';
import { documentsService } from '@/services/api/documentsService';
import { documentTypesService } from '@/services/api/documentTypesService';
import { metadataSchemaService } from '@/services/api/metadataSchemaService';
import  type { MetadataField } from '@/services/api/metadataSchemaService';
import { metadataExtractionService, type ExtractedMetadata } from '@/services/ai/metadataExtractionService';
import { DynamicMetadataForm } from './DynamicMetadataForm';
import BarcodeSelector from './BarcodeSelector';
import FolderSelector from './FolderSelector';
import WarehouseLocationSelector from './WarehouseLocationSelector';
// New Panel Components
import { FileListSidebar } from './FileListSidebar';
import { PreviewPanel } from './PreviewPanel';
import { ClassificationPanel } from './ClassificationPanel';
import { ExtractionPanel } from './ExtractionPanel';
import { MetadataPanel } from './MetadataPanel';
import { BarcodePanel } from './BarcodePanel';
import { LocationPanel } from './LocationPanel';
import {
  DocumentArrowUpIcon,
  FolderIcon,
  EyeIcon,
  TagIcon,
  Cog6ToothIcon,
  ArrowRightIcon,
  CheckIcon,
  ExclamationTriangleIcon,
  DocumentIcon,
  XMarkIcon,
  PhotoIcon,
  SparklesIcon
} from '@heroicons/react/24/outline';

interface EnhancedUploadInterfaceProps {
  className?: string;
  maxFileSize?: number;
  maxFiles?: number;
  allowedFileTypes?: string[];
  onUploadComplete?: (documents: any[]) => void;
}

interface FileWithPreview {
  id: string;
  file: File;
  preview?: string;
  documentTypeId?: string;
  documentTypeName?: string;
  classificationConfidence?: number;
  classificationReasoning?: string;
  metadata: Record<string, any>;
  extractedMetadata?: ExtractedMetadata;
  ocrText?: string;
  embeddings?: number[];
  barcodeId?: string;
  barcodeCode?: string;
  barcodeAutoGenerated?: boolean;
  folderId?: string;
  folderPath?: string;
  folderAutoAssigned?: boolean;
  rackId?: string;
  locationPath?: string;
  extractionStatus: 'pending' | 'extracting' | 'completed' | 'failed';
  classificationStatus: 'pending' | 'classifying' | 'completed' | 'failed';
  status: 'pending' | 'uploading' | 'success' | 'error';
  progress: number;
  error?: string;
}

export const EnhancedUploadInterface: React.FC<EnhancedUploadInterfaceProps> = ({
  className = '',
  maxFileSize = 50 * 1024 * 1024,
  maxFiles = 100,
  allowedFileTypes = [],
  onUploadComplete
}) => {
  const { theme } = useTheme();
  const [selectedFiles, setSelectedFiles] = useState<FileWithPreview[]>([]);
  const [selectedFileId, setSelectedFileId] = useState<string | null>(null);
  const [step, setStep] = useState<'upload' | 'preview' | 'classification' | 'extraction' | 'metadata' | 'barcode' | 'location' | 'processing'>('upload');
  const [documentTypes, setDocumentTypes] = useState<any[]>([]);
  const [metadataFields, setMetadataFields] = useState<MetadataField[]>([]);
  const [isProcessing, setIsProcessing] = useState(false);
  const [isExtracting, setIsExtracting] = useState(false);
  const [isClassifying, setIsClassifying] = useState(false);
  const [showOcrModal, setShowOcrModal] = useState(false);
  const [selectedOcrText, setSelectedOcrText] = useState<string>('');

  // Load document types on component mount
  React.useEffect(() => {
    loadDocumentTypes();
  }, []);

  const loadDocumentTypes = async () => {
    try {
      console.log('Loading document types...');
      const response = await documentTypesService.listDocumentTypes({ include_system: true });
      console.log('Document types loaded:', response.document_types);
      setDocumentTypes(response.document_types);
    } catch (error) {
      console.error('Failed to load document types:', error);
    }
  };

  // Load metadata fields when classification is completed
  React.useEffect(() => {
    const allFilesClassified = selectedFiles.length > 0 && selectedFiles.every(f => f.documentTypeId && f.classificationStatus === 'completed');
    if (allFilesClassified && (step === 'classification' || step === 'extraction' || step === 'metadata')) {
      // For simplicity, use the first file's document type to load schema
      const firstDocTypeId = selectedFiles[0].documentTypeId;
      if (firstDocTypeId && metadataFields.length === 0) {
        loadMetadataFields(firstDocTypeId);
      }
    }
  }, [selectedFiles, step, metadataFields.length]);

  const loadMetadataFields = async (documentTypeId: string) => {
    try {
      console.log('Loading metadata fields for document type:', documentTypeId);
      const schema = await metadataSchemaService.getSchemaByDocumentType(documentTypeId);
      console.log('Metadata schema loaded:', schema);
      setMetadataFields(schema.fields || []);

      // Initialize metadata with default values for all files
      setSelectedFiles(prev => prev.map(f => {
        const initialMetadata: Record<string, any> = { ...f.metadata };
        schema.fields?.forEach(field => {
          if (field.default_value && !initialMetadata[field.field_name]) {
            initialMetadata[field.field_name] = field.default_value;
          }
        });
        return { ...f, metadata: initialMetadata };
      }));
    } catch (error: any) {
      console.error('Failed to load metadata fields:', error);
      // If no schema exists, continue with empty fields
      setMetadataFields([]);
    }
  };

  const generatePreview = (file: File): Promise<string | undefined> => {
    return new Promise((resolve) => {
      if (file.type.startsWith('image/')) {
        const reader = new FileReader();
        reader.onload = () => resolve(reader.result as string);
        reader.onerror = () => resolve(undefined);
        reader.readAsDataURL(file);
      } else if (file.type === 'application/pdf') {
        const reader = new FileReader();
        reader.onload = () => resolve(reader.result as string);
        reader.onerror = () => resolve(undefined);
        reader.readAsDataURL(file);
      } else {
        resolve(undefined);
      }
    });
  };

  const getFileType = (file: File): 'image' | 'pdf' | 'other' => {
    if (file.type.startsWith('image/')) return 'image';
    if (file.type === 'application/pdf') return 'pdf';
    return 'other';
  };

  const getFileIcon = (file: File) => {
    const fileType = getFileType(file);
    if (fileType === 'image') {
      return <PhotoIcon className="h-5 w-5 text-blue-500 flex-shrink-0" />;
    } else if (fileType === 'pdf') {
      return <DocumentIcon className="h-5 w-5 text-red-500 flex-shrink-0" />;
    } else {
      return <DocumentIcon className="h-5 w-5 text-gray-400 flex-shrink-0" />;
    }
  };

  // Handle regular file selection
  const handleFilesAdded = useCallback(async (files: File[]) => {
    console.log('Files added:', files);
    const newFiles: FileWithPreview[] = [];

    for (const file of files) {
      const id = `${Date.now()}-${Math.random().toString(36).substr(2, 9)}`;
      const preview = await generatePreview(file);

      newFiles.push({
        id,
        file,
        preview,
        metadata: {},
        extractionStatus: 'pending',
        classificationStatus: 'pending',
        status: 'pending',
        progress: 0
      });
    }

    console.log('New files created:', newFiles);
    setSelectedFiles(prev => [...prev, ...newFiles]);

    if (newFiles.length > 0) {
      console.log('Moving to preview step');
      setStep('preview');
      setSelectedFileId(newFiles[0].id);
    }
  }, []);

  const updateFileMetadata = useCallback((fileId: string, metadata: Partial<FileWithPreview['metadata']>) => {
    setSelectedFiles(prev => prev.map(f =>
      f.id === fileId
        ? { ...f, metadata: { ...f.metadata, ...metadata } }
        : f
    ));
  }, []);

  const updateFileDocumentType = useCallback((fileId: string, documentTypeId: string) => {
    setSelectedFiles(prev => prev.map(f =>
      f.id === fileId
        ? { ...f, documentTypeId, metadata: {} }
        : f
    ));
  }, []);

  const removeFile = useCallback((fileId: string) => {
    setSelectedFiles(prev => prev.filter(f => f.id !== fileId));
    if (selectedFileId === fileId) {
      const remaining = selectedFiles.filter(f => f.id !== fileId);
      setSelectedFileId(remaining.length > 0 ? remaining[0].id : null);
    }
  }, [selectedFileId, selectedFiles]);

  const selectedFile = selectedFiles.find(f => f.id === selectedFileId);

  const allDocumentTypesSelected = selectedFiles.every(f => f.documentTypeId);

  const allMetadataComplete = selectedFiles.every(f => {
    if (!f.documentTypeId) return false;
    // Check if all required fields are filled
    const requiredFields = metadataFields.filter(field => field.is_required);
    return requiredFields.every(field => {
      const value = f.metadata[field.field_name];
      return value !== undefined && value !== null && value !== '';
    });
  });

  const allBarcodesAssigned = selectedFiles.every(f => f.barcodeId);
  const allLocationsAssigned = selectedFiles.every(f => f.folderId && f.rackId);

  // LLM Classification Step
  const classifyDocuments = useCallback(async () => {
    console.log('====================================');
    console.log('ðŸš€ Starting AI Classification Process');
    console.log('====================================');
    console.log(`Total files to classify: ${selectedFiles.length}`);
    console.log('Files:', selectedFiles.map(f => f.file.name));

    setIsClassifying(true);
    setStep('classification');

    for (let i = 0; i < selectedFiles.length; i++) {
      const fileData = selectedFiles[i];
      console.log(`\n--- Classifying File ${i + 1}/${selectedFiles.length} ---`);
      console.log(`ðŸ“„ File: ${fileData.file.name}`);
      console.log(`ðŸ“Š Size: ${(fileData.file.size / 1024).toFixed(2)} KB`);
      console.log(`ðŸ“‹ Type: ${fileData.file.type}`);

      try {
        console.log('â³ Setting status to "classifying"...');
        setSelectedFiles(prev => prev.map(f =>
          f.id === fileData.id ? { ...f, classificationStatus: 'classifying' as const } : f
        ));

        console.log('ðŸ“¦ Creating FormData...');
        const formData = new FormData();
        formData.append('file', fileData.file);
        formData.append('use_ocr', 'true');
        formData.append('process_first_page_only', 'true'); // Classification only needs page 1 for document type identification
        console.log('âœ… FormData created with file and use_ocr=true (first page only for classification)');

        console.log('ðŸŒ Sending request to backend API...');
        console.log('ðŸ”— URL: http://localhost:8001/api/v1/classification/classify');

        const startTime = performance.now();
        const response = await fetch('http://localhost:8001/api/v1/classification/classify', {
          method: 'POST',
          body: formData
        });
        const endTime = performance.now();

        console.log(`â±ï¸ Request completed in ${(endTime - startTime).toFixed(0)}ms`);
        console.log(`ðŸ“¡ Response status: ${response.status} ${response.statusText}`);

        console.log('ðŸ“¥ Parsing JSON response...');
        const result = await response.json();
        console.log('ðŸ“‹ Full API Response:', JSON.stringify(result, null, 2));

        if (result.success && result.classification) {
          console.log('âœ… Classification successful!');
          console.log(`ðŸ“Œ Document Type: ${result.classification.document_type_name}`);
          console.log(`ðŸ“Œ Document Type ID: ${result.classification.document_type_id}`);
          console.log(`ðŸ“Œ Confidence: ${(result.classification.confidence * 100).toFixed(1)}%`);
          console.log(`ðŸ“Œ Reasoning: ${result.classification.reasoning}`);
          console.log(`ðŸ“Œ OCR Performed: ${result.ocr_performed ? 'Yes' : 'No'}`);
          if (result.ocr_text) {
            console.log(`ðŸ“Œ OCR Text Length: ${result.ocr_text.length} characters`);
            console.log(`ðŸ“Œ OCR Text Preview: ${result.ocr_text.substring(0, 100)}...`);
          }

          setSelectedFiles(prev => prev.map(f =>
            f.id === fileData.id ? {
              ...f,
              documentTypeId: result.classification.document_type_id,
              documentTypeName: result.classification.document_type_name,
              classificationConfidence: result.classification.confidence,
              classificationReasoning: result.classification.reasoning,
              ocrText: result.ocr_text || undefined,
              classificationStatus: 'completed' as const
            } : f
          ));
          console.log('âœ… File state updated with classification results');
        } else {
          console.error('âŒ Classification failed - API returned success=false or missing classification');
          console.error('Error details:', result.error || 'No error message provided');
          setSelectedFiles(prev => prev.map(f =>
            f.id === fileData.id ? { ...f, classificationStatus: 'failed' as const } : f
          ));
        }
      } catch (error) {
        console.error('âŒ Classification error caught:', error);
        console.error('Error details:', {
          name: error instanceof Error ? error.name : 'Unknown',
          message: error instanceof Error ? error.message : String(error),
          stack: error instanceof Error ? error.stack : 'No stack trace'
        });
        setSelectedFiles(prev => prev.map(f =>
          f.id === fileData.id ? { ...f, classificationStatus: 'failed' as const } : f
        ));
      }
    }

    setIsClassifying(false);
    console.log('\n====================================');
    console.log('âœ… AI Classification Process Complete');
    console.log('====================================\n');
  }, [selectedFiles]);

  // Extract metadata from all files using AI with backend API
  // IMPORTANT: This processes ALL pages of multi-page documents
  // Classification stage only processed page 1 for document type identification
  // This stage converts ALL pages to images and sends to LLM in a single call for:
  //   1. Metadata field extraction (based on document type schema)
  //   2. Formatted Vision/OCR text extraction (from all pages)
  //   3. Semantic embeddings generation (for RAG)
  const extractMetadataFromFiles = useCallback(async () => {
    if (selectedFiles.length === 0) return;

    setIsExtracting(true);
    setStep('extraction');

    console.log('====================================');
    console.log('ðŸš€ Starting Full Document AI Extraction');
    console.log('====================================');
    console.log('Processing', selectedFiles.length, 'files with ALL pages');
    console.log('Expected output: Metadata + OCR (all pages) + Embeddings');

    for (const fileData of selectedFiles) {
      try {
        // Update extraction status
        setSelectedFiles(prev => prev.map(f =>
          f.id === fileData.id
            ? { ...f, extractionStatus: 'extracting' as const }
            : f
        ));

        console.log('Extracting metadata for:', fileData.file.name, 'Type:', fileData.documentTypeName);

        // Call backend metadata extraction API with schema support
        // This single API call should:
        // 1. Convert ALL pages of PDF to images (not just page 1)
        // 2. Send all pages to LLM in single call
        // 3. Return: metadata fields + complete OCR/Vision text from ALL pages + embeddings
        const formData = new FormData();
        formData.append('file', fileData.file); // Complete file
        formData.append('document_type_id', fileData.documentTypeId || '');
        formData.append('process_all_pages', 'true'); // CRITICAL: Process all pages, not just first page
        formData.append('include_embeddings', 'true'); // Request embeddings generation
        formData.append('include_vision_ocr', 'true'); // Request formatted vision/OCR text
        if (fileData.ocrText) {
          formData.append('classification_ocr_text', fileData.ocrText); // OCR from page 1 (classification stage)
        }

        console.log('ðŸš€ Starting full document extraction (all pages)...');
        console.log('  - Document Type:', fileData.documentTypeName);
        console.log('  - Processing: ALL pages');

        const response = await fetch('http://localhost:8001/api/v1/metadata/extract', {
          method: 'POST',
          body: formData
        });

        const result = await response.json();

        console.log('ðŸ“‹ Full extraction response:', result);

        if (result.success) {
          // Update file with all extraction data from ALL pages
          const fullOcrText = result.ocr_text || result.vision_text || result.formatted_text || f.ocrText;

          setSelectedFiles(prev => prev.map(f =>
            f.id === fileData.id
              ? {
                  ...f,
                  extractedMetadata: result,
                  extractionStatus: 'completed' as const,
                  metadata: {
                    ...f.metadata,
                    ...(result.extracted_fields || {}) // Metadata fields from schema-based extraction
                  },
                  ocrText: fullOcrText, // Full document OCR/Vision text from ALL pages
                  embeddings: result.embeddings || undefined // Semantic embeddings for RAG
                }
              : f
          ));

          console.log('âœ… Full document extraction complete for', fileData.file.name);
          console.log('  ðŸ“Š Metadata fields extracted:', Object.keys(result.extracted_fields || {}));
          console.log('  ðŸ“„ OCR text (all pages):', fullOcrText ? `${fullOcrText.length} characters` : 'None');
          console.log('  ðŸ”¢ Embeddings:', result.embeddings ? `${result.embeddings.length} dimensions` : 'None');
          console.log('  ðŸ“‘ Pages processed:', result.pages_processed || 'Unknown');
        } else {
          // No schema or extraction failed
          console.warn('âš ï¸ Extraction failed for', fileData.file.name, ':', result.error || 'Unknown error');
          setSelectedFiles(prev => prev.map(f =>
            f.id === fileData.id
              ? { ...f, extractionStatus: 'failed' as const }
              : f
          ));
        }

      } catch (error) {
        console.error('Failed to extract metadata for', fileData.file.name, ':', error);

        // Mark extraction as failed
        setSelectedFiles(prev => prev.map(f =>
          f.id === fileData.id
            ? { ...f, extractionStatus: 'failed' as const }
            : f
        ));
      }
    }

    setIsExtracting(false);
    setStep('metadata');

    // Auto-select first file for metadata review
    if (selectedFiles.length > 0 && !selectedFileId) {
      setSelectedFileId(selectedFiles[0].id);
    }

    console.log('\n====================================');
    console.log('âœ… Full Document AI Extraction Complete');
    console.log('====================================');
    console.log('All metadata, OCR text (all pages), and embeddings are now available in the Metadata step');
  }, [selectedFiles, selectedFileId]);

  // Extract metadata with OCR (for future use)
  const extractMetadataWithOCR = useCallback(async () => {
    if (selectedFiles.length === 0) return;

    setIsExtracting(true);
    setStep('extraction');

    for (const fileData of selectedFiles) {
      try {
        setSelectedFiles(prev => prev.map(f =>
          f.id === fileData.id
            ? { ...f, extractionStatus: 'extracting' as const }
            : f
        ));

        const extractedMetadata = await metadataExtractionService.extractMetadataWithOCR(
          fileData.file,
          { includeOCR: true }
        );

        setSelectedFiles(prev => prev.map(f =>
          f.id === fileData.id
            ? {
                ...f,
                extractedMetadata,
                extractionStatus: 'completed' as const,
                metadata: {
                  ...f.metadata,
                  category: extractedMetadata.category || f.metadata.category,
                  documentNumber: extractedMetadata.documentNumber || f.metadata.documentNumber
                }
              }
            : f
        ));

      } catch (error) {
        console.error('Failed to extract metadata with OCR for', fileData.file.name, ':', error);
        setSelectedFiles(prev => prev.map(f =>
          f.id === fileData.id
            ? { ...f, extractionStatus: 'failed' as const }
            : f
        ));
      }
    }

    setIsExtracting(false);
    setStep('metadata');
  }, [selectedFiles]);

  // Start upload process with embeddings and all metadata
  const handleStartUpload = useCallback(async () => {
    setIsProcessing(true);
    setStep('processing');

    const uploadedDocuments = [];

    for (const fileData of selectedFiles) {
      try {
        setSelectedFiles(prev => prev.map(f =>
          f.id === fileData.id ? { ...f, status: 'uploading' as const, progress: 0 } : f
        ));

        // Use embeddings from extraction (already generated during metadata extraction step)
        const embeddings = fileData.embeddings || null;

        console.log('================================================================================');
        console.log('FRONTEND: Starting document upload workflow');
        console.log('================================================================================');
        console.log('ðŸ“„ File Information:');
        console.log(`  - Filename: ${fileData.file.name}`);
        console.log(`  - File Size: ${fileData.file.size} bytes`);
        console.log(`  - File Type: ${fileData.file.type}`);

        console.log('\nðŸ¤– AI Classification Data:');
        console.log(`  - Document Type ID: ${fileData.documentTypeId || 'Not classified'}`);
        console.log(`  - Classification Confidence: ${fileData.classificationConfidence || 'N/A'}`);
        console.log(`  - Classification Reasoning: ${fileData.classificationReasoning ? 'Available' : 'None'}`);

        console.log('\nðŸ“¦ Location Data:');
        console.log(`  - Barcode ID: ${fileData.barcodeId || 'Not assigned'}`);
        console.log(`  - Folder ID (Digital): ${fileData.folderId || 'Not assigned'}`);
        console.log(`  - Folder Path (Digital): ${fileData.folderPath || 'Not assigned'}`);
        console.log(`  - Rack ID (Physical): ${fileData.rackId || 'Not assigned'}`);
        console.log(`  - Warehouse Path (Physical): ${fileData.locationPath || 'Not assigned'}`);

        console.log('\nðŸ” Extracted Data:');
        console.log(`  - OCR Text Length: ${fileData.ocrText?.length || 0} characters`);
        console.log(`  - Embeddings: ${embeddings ? `âœ“ ${embeddings.length} dimensions` : 'âœ— None'}`);
        console.log(`  - Custom Metadata Fields: ${fileData.metadata ? Object.keys(fileData.metadata).length : 0}`);
        if (fileData.metadata && Object.keys(fileData.metadata).length > 0) {
          console.log(`  - Metadata Keys: ${Object.keys(fileData.metadata).join(', ')}`);
        }

        console.log('\nðŸ¤– AI Features:');
        console.log(`  - Insights: ${fileData.extractedMetadata?.insights?.length || 0}`);
        console.log(`  - Summary: ${fileData.extractedMetadata?.summary ? 'Yes' : 'No'}`);
        console.log(`  - Key Terms: ${fileData.extractedMetadata?.key_terms?.length || 0}`);

        console.log('\nâ« Sending upload request to backend...');

        const result = await documentsService.uploadFile(
          fileData.file,
          {
            folderId: fileData.folderId,  // Top-level folder ID for backend
            metadata: {
              title: fileData.file.name,
              document_type_id: fileData.documentTypeId,
              document_type: fileData.documentTypeName,  // Document type name string
              barcode_id: fileData.barcodeId,
              folder_path: fileData.folderPath,
              rack_id: fileData.rackId,
              location_path: fileData.locationPath,
              ocr_text: fileData.ocrText,  // Pre-extracted OCR text
              ...fileData.metadata,  // Custom metadata fields from extraction
              classification_confidence: fileData.classificationConfidence,
              classification_reasoning: fileData.classificationReasoning
            },
            embeddings,
            // Pre-extracted AI features from metadata extraction
            insights: fileData.extractedMetadata?.insights || [],
            summary: fileData.extractedMetadata?.summary || {},
            key_terms: fileData.extractedMetadata?.key_terms || [],
            autoOcr: false, // OCR already done during extraction
            autoClassify: false // Classification already done
          },
          (progress) => {
            if (progress.percentage % 25 === 0 || progress.percentage === 100) {
              console.log(`ðŸ“Š Upload progress: ${progress.percentage}%`);
            }
            setSelectedFiles(prev => prev.map(f =>
              f.id === fileData.id
                ? { ...f, progress: progress.percentage }
                : f
            ));
          }
        );

        console.log('\nâœ… Backend Response Received:');
        console.log(`  - Success: ${result.success}`);
        if (result.success) {
          console.log(`  - Document ID: ${result.data?.id || 'N/A'}`);
          console.log(`  - Title: ${result.data?.title || 'N/A'}`);
          console.log(`  - Status: ${result.data?.status || 'N/A'}`);
        } else {
          console.log(`  - Error: ${result.error || 'Unknown error'}`);
        }
        console.log('================================================================================');

        if (result.success) {
          setSelectedFiles(prev => prev.map(f =>
            f.id === fileData.id
              ? { ...f, status: 'success' as const, progress: 100 }
              : f
          ));
          uploadedDocuments.push(result);
        } else {
          setSelectedFiles(prev => prev.map(f =>
            f.id === fileData.id
              ? { ...f, status: 'error' as const, error: result.error }
              : f
          ));
        }
      } catch (error) {
        console.error('âŒ Upload error:', error);
        console.error('Error details:', {
          message: (error as Error).message,
          stack: (error as Error).stack
        });
        setSelectedFiles(prev => prev.map(f =>
          f.id === fileData.id
            ? { ...f, status: 'error' as const, error: (error as Error).message }
            : f
        ));
      }
    }

    setIsProcessing(false);

    // Final summary
    console.log('\n\n');
    console.log('================================================================================');
    console.log('ðŸŽ‰ UPLOAD WORKFLOW COMPLETE');
    console.log('================================================================================');
    console.log(`Total Files Processed: ${selectedFiles.length}`);
    console.log(`Successful Uploads: ${uploadedDocuments.length}`);
    console.log(`Failed Uploads: ${selectedFiles.length - uploadedDocuments.length}`);
    if (uploadedDocuments.length > 0) {
      console.log('\nUploaded Document IDs:');
      uploadedDocuments.forEach((doc, index) => {
        console.log(`  ${index + 1}. ${doc.data?.id || 'N/A'} - ${doc.data?.title || 'Unknown'}`);
      });
    }
    console.log('================================================================================');
    console.log('\n\n');

    if (onUploadComplete) {
      onUploadComplete(uploadedDocuments);
    }

    setTimeout(() => {
      setSelectedFiles([]);
      setStep('upload');
      setSelectedFileId(null);
    }, 2000);
  }, [selectedFiles, onUploadComplete]);

  // Step Navigation
  const renderStepIndicator = () => (
    <div className="flex items-center justify-center space-x-2 mb-8 overflow-x-auto">
      {[
        { key: 'upload', label: 'Upload' },
        { key: 'preview', label: 'Preview' },
        { key: 'classification', label: 'AI Classify' },
        { key: 'extraction', label: 'AI Extract' },
        { key: 'metadata', label: 'Metadata' },
        { key: 'barcode', label: 'Barcode' },
        { key: 'location', label: 'Location' },
        { key: 'processing', label: 'Process' }
      ].map((stepInfo, index) => (
        <div key={stepInfo.key} className="flex items-center">
          <div
            className={`w-8 h-8 rounded-full flex items-center justify-center text-xs font-medium ${
              step === stepInfo.key
                ? 'bg-blue-600 text-white'
                : 'bg-gray-700 text-white'
            }`}
          >
            {index + 1}
          </div>
          <span className="ml-1 text-xs font-medium text-white hidden sm:inline">
            {stepInfo.label}
          </span>
          {index < 7 && (
            <ArrowRightIcon className="mx-2 h-3 w-3 text-gray-400" />
          )}
        </div>
      ))}
    </div>
  );

  // OCR Results Modal Component
  const OCRResultsModal = () => (
    <div className="fixed inset-0 bg-black bg-opacity-50 flex items-center justify-center z-50">
      <div className="bg-white rounded-lg p-6 max-w-4xl max-h-[80vh] w-full mx-4">
        <div className="flex justify-between items-center mb-4">
          <h3 className="text-lg font-medium text-gray-900">OCR Extraction Results</h3>
          <button
            onClick={() => setShowOcrModal(false)}
            className="text-gray-400 hover:text-gray-600"
          >
            <XMarkIcon className="h-6 w-6" />
          </button>
        </div>
        <div className="max-h-[60vh] overflow-y-auto">
          <div className="bg-gray-50 rounded-lg p-4 border">
            <h4 className="text-sm font-medium text-gray-700 mb-2">Extracted Text:</h4>
            <pre className="text-sm text-gray-800 whitespace-pre-wrap font-mono leading-relaxed break-words">
              {selectedOcrText || 'No OCR text available for this document.'}
            </pre>
          </div>
          {selectedOcrText && (
            <div className="mt-3 text-xs text-gray-500">
              Character count: {selectedOcrText.length} |
              Lines: {selectedOcrText.split('\n').length}
            </div>
          )}
        </div>
        <div className="mt-4 flex justify-end">
          <button
            onClick={() => setShowOcrModal(false)}
            className="px-4 py-2 text-sm font-medium text-gray-700 bg-gray-100 hover:bg-gray-200 rounded-md"
          >
            Close
          </button>
        </div>
      </div>
    </div>
  );

  const renderContent = () => {
    // Upload Step - Full Width
    if (step === 'upload') {
      return (
        <div className="space-y-6">
          <UploadZone
            onFilesAdded={handleFilesAdded}
            maxFileSize={maxFileSize}
            maxFiles={maxFiles}
            accept={allowedFileTypes.join(',')}
            className="border-2 border-dashed border-gray-300 rounded-lg p-6 hover:border-blue-400 transition-colors"
          />
        </div>
      );
    }

    // 3-Column Layout for Preview, Classification, Extraction, Metadata, Barcode, Location Steps
    if (['preview', 'classification', 'extraction', 'metadata', 'barcode', 'location'].includes(step)) {
      return (
        <div className="h-full grid grid-cols-12 gap-4">
          {/* Left Sidebar - File List (20%) */}
          <div className="col-span-12 lg:col-span-2 h-full overflow-hidden">
            <FileListSidebar
              files={selectedFiles}
              selectedFileId={selectedFileId}
              onFileSelect={setSelectedFileId}
              onRemoveFile={removeFile}
              currentStep={step}
              metadataFields={metadataFields}
            />
          </div>

          {/* Center - Preview (40%) */}
          <div className="col-span-12 lg:col-span-5 h-full overflow-hidden">
            <PreviewPanel file={selectedFile || null} />
          </div>

          {/* Right - Step Content (40%) */}
          <div className="col-span-12 lg:col-span-5 h-full overflow-hidden">
            {step === 'preview' && (
              <div className="text-center p-8">
                <h3 className="text-lg font-medium text-white mb-4">Ready to Process</h3>
                <p className="text-sm text-gray-400 mb-6">
                  Review your files in the preview panel. When ready, click "Start AI Classification" below to begin processing.
                </p>
                <div className="bg-blue-900/20 border border-blue-500 rounded-lg p-4">
                  <p className="text-xs text-blue-300">
                    <span className="font-semibold">Next Step:</span> AI will analyze each document to identify its type, extract metadata, and generate searchable content.
                  </p>
                </div>
              </div>
            )}

            {step === 'classification' && (
              <ClassificationPanel
                file={selectedFile || null}
                documentTypes={documentTypes}
                isClassifying={isClassifying}
                allFiles={selectedFiles}
              />
            )}

            {step === 'extraction' && (
              <ExtractionPanel
                file={selectedFile || null}
                isExtracting={isExtracting}
                allFiles={selectedFiles}
              />
            )}

            {step === 'metadata' && (
              <MetadataPanel
                file={selectedFile || null}
                metadataFields={metadataFields}
                onMetadataChange={(fieldName, value) => {
                  if (selectedFile) {
                    updateFileMetadata(selectedFile.id, { [fieldName]: value });
                  }
                }}
                onViewOcr={(ocrText) => {
                  setSelectedOcrText(ocrText);
                  setShowOcrModal(true);
                }}
              />
            )}

            {step === 'barcode' && (
              <BarcodePanel
                file={selectedFile || null}
                onBarcodeSelect={(barcodeId, barcodeCode, autoGenerated = false) => {
                  if (selectedFile) {
                    setSelectedFiles(prev => prev.map(f =>
                      f.id === selectedFile.id ? { ...f, barcodeId, barcodeCode, barcodeAutoGenerated: autoGenerated } : f
                    ));
                  }
                }}
                allFiles={selectedFiles}
              />
            )}

            {step === 'location' && (
              <LocationPanel
                file={selectedFile || null}
                onFolderSelect={(folderId, folderPath, autoAssigned = false) => {
                  if (selectedFile) {
                    setSelectedFiles(prev => prev.map(f =>
                      f.id === selectedFile.id ? { ...f, folderId, folderPath, folderAutoAssigned: autoAssigned } : f
                    ));
                  }
                }}
                onRackSelect={(rackId, locationPath) => {
                  if (selectedFile) {
                    setSelectedFiles(prev => prev.map(f =>
                      f.id === selectedFile.id ? { ...f, rackId, locationPath } : f
                    ));
                  }
                }}
                allFiles={selectedFiles}
              />
            )}
          </div>
        </div>
      );
    }

    // Processing Step - Full Width
    if (step === 'processing') {
      return (
        <div className="space-y-6">
          <div className="text-center">
            <h3 className="text-lg font-medium mb-4 text-white">
              Processing Documents
            </h3>
            <p className={`text-sm ${
              theme === 'dark' ? 'text-gray-300' : 'text-gray-600'
            }`}>
              Uploading files to Pie-Docs with metadata...
            </p>
          </div>

          <div className="space-y-4">
            {selectedFiles.map((file) => (
              <div key={file.id} className="border rounded-lg p-4">
                <div className="flex items-center justify-between mb-2">
                  <div className="flex items-center space-x-2">
                    <DocumentIcon className="h-5 w-5 text-gray-400" />
                    <span className="text-sm font-medium text-white">
                      {file.file.name}
                    </span>
                  </div>
                  <div className="flex items-center space-x-2">
                    {file.status === 'success' && (
                      <CheckIcon className="h-5 w-5 text-green-500" />
                    )}
                    {file.status === 'error' && (
                      <ExclamationTriangleIcon className="h-5 w-5 text-red-500" />
                    )}
                    <span className={`text-sm ${
                      theme === 'dark' ? 'text-gray-300' : 'text-gray-600'
                    }`}>
                      {file.status === 'uploading' && `${file.progress}%`}
                      {file.status === 'success' && 'Complete'}
                      {file.status === 'error' && 'Failed'}
                    </span>
                  </div>
                </div>

                {file.status === 'uploading' && (
                  <div className="w-full bg-gray-200 rounded-full h-2">
                    <div
                      className="bg-blue-600 h-2 rounded-full transition-all duration-300"
                      style={{ width: `${file.progress}%` }}
                    />
                  </div>
                )}

                {file.error && (
                  <p className="text-sm text-red-600 mt-2">{file.error}</p>
                )}

                <div className={`text-xs mt-2 ${
                  theme === 'dark' ? 'text-gray-400' : 'text-gray-500'
                }`}>
                  Category: {file.metadata.category} | Document Number: {file.metadata.documentNumber}
                </div>
              </div>
            ))}
          </div>
        </div>
      );
    }

    return null;
  };

  return (
    <div className={`flex items-center justify-center w-full ${className}`}>
      <div className="w-full h-[70vh] flex flex-col bg-gray-900 rounded-xl shadow-2xl p-6">
        {/* Step Indicator */}
        {renderStepIndicator()}

        {/* Step Content */}
        <div className="flex-1 overflow-y-auto">
          {renderContent()}
        </div>

        {/* Navigation */}
        <div className="flex justify-between pt-6 mt-auto">
          <button
            onClick={() => {
              if (step === 'preview') setStep('upload');
              if (step === 'classification') setStep('preview');
              if (step === 'extraction') setStep('classification');
              if (step === 'metadata') setStep('extraction');
              if (step === 'barcode') setStep('metadata');
              if (step === 'location') setStep('barcode');
            }}
            disabled={step === 'upload' || step === 'processing'}
            className={`px-4 py-2 text-sm font-medium border rounded-md disabled:opacity-50 disabled:cursor-not-allowed ${
              theme === 'dark'
                ? 'text-gray-200 bg-gray-800 hover:bg-gray-700 border-gray-600'
                : 'text-gray-700 bg-white hover:bg-gray-50'
            }`}
          >
            Back
          </button>

          {step === 'upload' && selectedFiles.length > 0 && (
            <button
              onClick={() => setStep('preview')}
              className="px-4 py-2 text-sm font-medium text-white bg-blue-600 border border-transparent rounded-md hover:bg-blue-700"
            >
              Continue
            </button>
          )}

          {step === 'preview' && selectedFiles.length > 0 && (
            <button
              onClick={classifyDocuments}
              disabled={selectedFiles.length === 0}
              className="inline-flex items-center px-4 py-2 border border-transparent text-sm font-medium rounded-md text-white bg-blue-600 hover:bg-blue-700 disabled:bg-gray-400"
            >
              <SparklesIcon className="h-4 w-4 mr-2" />
              Start AI Classification
              <ArrowRightIcon className="ml-2 h-4 w-4" />
            </button>
          )}

          {step === 'classification' && !isClassifying && (
            <button
              onClick={extractMetadataFromFiles}
              className="inline-flex items-center px-6 py-3 text-base font-medium text-white bg-blue-600 hover:bg-blue-700 rounded-md"
            >
              Continue to Metadata Extraction
              <ArrowRightIcon className="ml-2 h-5 w-5" />
            </button>
          )}

          {step === 'metadata' && (
            <button
              onClick={() => setStep('barcode')}
              disabled={!allMetadataComplete}
              className="inline-flex items-center px-4 py-2 border border-transparent text-sm font-medium rounded-md text-white bg-blue-600 hover:bg-blue-700 disabled:bg-gray-400 disabled:cursor-not-allowed"
            >
              Next: Barcode Assignment
              <ArrowRightIcon className="ml-2 h-4 w-4" />
            </button>
          )}

          {step === 'barcode' && (
            <button
              onClick={() => setStep('location')}
              disabled={!allBarcodesAssigned}
              className="inline-flex items-center px-4 py-2 border border-transparent text-sm font-medium rounded-md text-white bg-blue-600 hover:bg-blue-700 disabled:bg-gray-400 disabled:cursor-not-allowed"
            >
              Next: Location Assignment
              <ArrowRightIcon className="ml-2 h-4 w-4" />
            </button>
          )}

          {step === 'location' && (
            <button
              onClick={handleStartUpload}
              disabled={!allLocationsAssigned || isProcessing}
              className="inline-flex items-center px-4 py-2 border border-transparent text-sm font-medium rounded-md text-white bg-green-600 hover:bg-green-700 disabled:bg-gray-400 disabled:cursor-not-allowed"
            >
              Complete Upload
              <CheckIcon className="ml-2 h-4 w-4" />
            </button>
          )}
        </div>
      </div>

      {/* OCR Results Modal */}
      {showOcrModal && <OCRResultsModal />}
    </div>
  );
};

export default EnhancedUploadInterface;